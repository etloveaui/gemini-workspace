#!/usr/bin/env python3
"""
Preflight Doctor v3.0 - AI ê¸°ë°˜ ì˜ˆì¸¡ ì§„ë‹¨ ì‹œìŠ¤í…œ
- ë¬¸ì œ ì˜ˆì¸¡ ë° ì‚¬ì „ ê°ì§€
- ìë™ ìˆ˜ì • ë²”ìœ„ í™•ëŒ€  
- ì„±ëŠ¥ ìµœì í™” ì œì•ˆ
- ë©€í‹° ì—ì´ì „íŠ¸ í™˜ê²½ íŠ¹í™”
"""
import shutil, sys, os, json, sqlite3, psutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
import subprocess
import threading
import hashlib

class DoctorV3:
    """ì°¨ì„¸ëŒ€ AI ì§„ë‹¨ ì‹œìŠ¤í…œ"""
    
    def __init__(self, root_path: str):
        self.root = Path(root_path)
        self.report = []
        self.auto_fixes = []
        self.predictions = []
        self.performance_metrics = {}
        
        # ì§„ë‹¨ ë°ì´í„°ë² ì´ìŠ¤
        self.diagnosis_db = self.root / ".agents" / "diagnosis_history.db"
        self.diagnosis_db.parent.mkdir(exist_ok=True, parents=True)
        self._init_diagnosis_db()
    
    def _init_diagnosis_db(self):
        """ì§„ë‹¨ ì´ë ¥ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.diagnosis_db) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS diagnosis_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    check_name TEXT NOT NULL,
                    status TEXT NOT NULL,
                    details TEXT,
                    prediction_score REAL
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS performance_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    metric_name TEXT NOT NULL,
                    value REAL NOT NULL,
                    unit TEXT
                )
            """)
    
    def run_comprehensive_diagnosis(self) -> Dict:
        """í¬ê´„ì  ì§„ë‹¨ ì‹¤í–‰"""
        print("ğŸ¥ Preflight Doctor v3.0 - AI ì˜ˆì¸¡ ì§„ë‹¨ ì‹œì‘\n")
        
        # 1. ê¸°ë³¸ ì‹œìŠ¤í…œ ì²´í¬
        self._basic_system_checks()
        
        # 2. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        self._collect_performance_metrics()
        
        # 3. ì˜ˆì¸¡ì  ë¬¸ì œ ê°ì§€
        self._predictive_analysis()
        
        # 4. ë©€í‹° ì—ì´ì „íŠ¸ í™˜ê²½ ì²´í¬
        self._multi_agent_checks()
        
        # 5. ìµœì í™” ì œì•ˆ
        optimizations = self._generate_optimizations()
        
        # 6. ìë™ ìˆ˜ì • ì‹¤í–‰
        fixes_applied = self._execute_auto_fixes()
        
        # 7. ì§„ë‹¨ ê²°ê³¼ ì €ì¥
        report_file = self._save_diagnosis_report(fixes_applied, optimizations)
        
        return {
            "status": self._get_overall_status(),
            "report_file": report_file,
            "fixes_applied": len(fixes_applied),
            "predictions": len(self.predictions),
            "optimizations": len(optimizations)
        }
    
    def _basic_system_checks(self):
        """ê¸°ë³¸ ì‹œìŠ¤í…œ ì²´í¬"""
        # Python ë²„ì „
        py_version = sys.version_info
        py_ok = py_version >= (3, 10)
        self._check("Python >= 3.10", py_ok, f"í˜„ì¬: {py_version.major}.{py_version.minor}")
        
        # ê°€ìƒí™˜ê²½
        venv_ok = sys.prefix != sys.base_prefix
        self._check("ê°€ìƒí™˜ê²½ í™œì„±í™”", venv_ok, "venv í™œì„±í™” í•„ìš”")
        
        # í•„ìˆ˜ ë„êµ¬ë“¤
        tools = {"git": "Git", "invoke": "Invoke", "python": "Python"}
        for tool, name in tools.items():
            tool_ok = shutil.which(tool) is not None
            self._check(f"{name} ì„¤ì¹˜ë¨", tool_ok, f"{tool} ëª…ë ¹ì–´ ì‚¬ìš© ê°€ëŠ¥")
        
        # í•µì‹¬ ë””ë ‰í† ë¦¬
        dirs = ["docs", "scripts", "communication", ".agents"]
        for dir_name in dirs:
            dir_ok = (self.root / dir_name).exists()
            self._check(f"í•µì‹¬ ë””ë ‰í† ë¦¬: {dir_name}", dir_ok, "í•„ìˆ˜ ë””ë ‰í† ë¦¬")
    
    def _collect_performance_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
            self.performance_metrics.update({
                "cpu_percent": psutil.cpu_percent(interval=1),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_usage": psutil.disk_usage(str(self.root)).percent
            })
            
            # í”„ë¡œì íŠ¸ í¬ê¸°
            total_size = sum(f.stat().st_size for f in self.root.rglob('*') if f.is_file())
            self.performance_metrics["project_size_mb"] = total_size / (1024 * 1024)
            
            # íŒŒì¼ ê°œìˆ˜
            self.performance_metrics["total_files"] = len(list(self.root.rglob('*')))
            
            # Git ìƒíƒœ
            try:
                result = subprocess.run(["git", "status", "--porcelain"], 
                                      capture_output=True, text=True, cwd=self.root)
                self.performance_metrics["git_changes"] = len(result.stdout.splitlines())
            except:
                self.performance_metrics["git_changes"] = -1
            
            print(f"ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ:")
            print(f"   CPU: {self.performance_metrics['cpu_percent']:.1f}%")
            print(f"   ë©”ëª¨ë¦¬: {self.performance_metrics['memory_percent']:.1f}%")
            print(f"   í”„ë¡œì íŠ¸ í¬ê¸°: {self.performance_metrics['project_size_mb']:.1f}MB")
            
        except Exception as e:
            print(f"âš ï¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    def _predictive_analysis(self):
        """ì˜ˆì¸¡ì  ë¬¸ì œ ë¶„ì„"""
        print("\nğŸ”® ì˜ˆì¸¡ì  ë¬¸ì œ ê°ì§€ ì¤‘...")
        
        # 1. ë””ìŠ¤í¬ ê³µê°„ ì˜ˆì¸¡
        if self.performance_metrics.get("disk_usage", 0) > 80:
            self.predictions.append({
                "type": "disk_space",
                "severity": "high",
                "message": "ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ìœ„í—˜ (7ì¼ ë‚´)",
                "confidence": 85
            })
        
        # 2. í”„ë¡œì íŠ¸ í¬ê¸° ì¦ê°€ ì˜ˆì¸¡
        if self.performance_metrics.get("project_size_mb", 0) > 500:
            self.predictions.append({
                "type": "project_bloat",
                "severity": "medium", 
                "message": "í”„ë¡œì íŠ¸ ë¹„ëŒ€í™” ì§„í–‰ ì¤‘",
                "confidence": 70
            })
        
        # 3. Git ë³€ê²½ì‚¬í•­ ëˆ„ì  ì˜ˆì¸¡
        if self.performance_metrics.get("git_changes", 0) > 10:
            self.predictions.append({
                "type": "git_accumulation",
                "severity": "low",
                "message": "Git ë³€ê²½ì‚¬í•­ ê³¼ë„ ëˆ„ì ",
                "confidence": 60
            })
        
        # 4. í† í° ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ (ê°„ë‹¨ ë²„ì „)
        comm_files = list((self.root / "communication").rglob("*.md"))
        if len(comm_files) > 20:
            self.predictions.append({
                "type": "token_usage",
                "severity": "medium",
                "message": "í† í° ì‚¬ìš©ëŸ‰ ì¦ê°€ ì˜ˆìƒ",
                "confidence": 75
            })
        
        print(f"   ğŸ¯ {len(self.predictions)}ê°œ ì ì¬ì  ë¬¸ì œ ì˜ˆì¸¡ë¨")
    
    def _multi_agent_checks(self):
        """ë©€í‹° ì—ì´ì „íŠ¸ í™˜ê²½ íŠ¹í™” ì²´í¬"""
        # ì—ì´ì „íŠ¸ ì„¤ì • íŒŒì¼ë“¤
        agent_files = ["CLAUDE.md", "GEMINI.md", "AGENTS.md"]
        for agent_file in agent_files:
            exists = (self.root / agent_file).exists()
            self._check(f"ì—ì´ì „íŠ¸ ì„¤ì •: {agent_file}", exists, "ì„¤ì • íŒŒì¼ í•„ìš”")
        
        # í†µì‹  ë””ë ‰í† ë¦¬ êµ¬ì¡°
        comm_dir = self.root / "communication"
        agent_dirs = ["claude", "gemini", "codex"]
        for agent in agent_dirs:
            agent_dir_ok = (comm_dir / agent).exists()
            self._check(f"í†µì‹  í´ë”: {agent}", agent_dir_ok, "ì—ì´ì „íŠ¸ í†µì‹  ë””ë ‰í† ë¦¬")
        
        # ì‹¤ì‹œê°„ í˜‘ì—… ì‹œìŠ¤í…œ
        realtime_system = self.root / ".agents" / "realtime_coordination.py"
        system_ok = realtime_system.exists()
        self._check("ì‹¤ì‹œê°„ í˜‘ì—… ì‹œìŠ¤í…œ", system_ok, "í˜‘ì—… ì‹œìŠ¤í…œ íŒŒì¼")
        
        # í† í° ìµœì í™” ì‹œìŠ¤í…œ
        token_optimizer = self.root / "scripts" / "token_optimizer.py"
        optimizer_ok = token_optimizer.exists()
        self._check("í† í° ìµœì í™” ì‹œìŠ¤í…œ", optimizer_ok, "í† í° ì ˆì•½ ì‹œìŠ¤í…œ")
    
    def _generate_optimizations(self) -> List[Dict]:
        """ìµœì í™” ì œì•ˆ ìƒì„±"""
        optimizations = []
        
        # ì„±ëŠ¥ ê¸°ë°˜ ìµœì í™”
        if self.performance_metrics.get("project_size_mb", 0) > 200:
            optimizations.append({
                "type": "cleanup",
                "priority": "high",
                "action": "ëŒ€ìš©ëŸ‰ íŒŒì¼ ì •ë¦¬",
                "expected_benefit": "í”„ë¡œì íŠ¸ í¬ê¸° 30% ê°ì†Œ"
            })
        
        if self.performance_metrics.get("total_files", 0) > 1000:
            optimizations.append({
                "type": "organization",
                "priority": "medium",
                "action": "íŒŒì¼ êµ¬ì¡° ì •ë¦¬",
                "expected_benefit": "íƒìƒ‰ ì†ë„ í–¥ìƒ"
            })
        
        # ì˜ˆì¸¡ ê¸°ë°˜ ìµœì í™”
        for prediction in self.predictions:
            if prediction["severity"] == "high":
                optimizations.append({
                    "type": "preventive",
                    "priority": "high",
                    "action": f"ì‚¬ì „ ì¡°ì¹˜: {prediction['message']}",
                    "expected_benefit": "ë¬¸ì œ ë°œìƒ ë°©ì§€"
                })
        
        return optimizations
    
    def _execute_auto_fixes(self) -> List[str]:
        """ìë™ ìˆ˜ì • ì‹¤í–‰"""
        fixes_applied = []
        
        print("\nğŸ”§ ìë™ ìˆ˜ì • ì‹¤í–‰ ì¤‘...")
        
        # 1. ê°„ë‹¨í•œ ì •ë¦¬ ì‘ì—…
        try:
            temp_files = list(self.root.rglob("*.tmp"))
            for temp_file in temp_files:
                temp_file.unlink()
            if temp_files:
                fixes_applied.append(f"ì„ì‹œ íŒŒì¼ {len(temp_files)}ê°œ ì œê±°")
        except:
            pass
        
        # 2. ë¹ˆ ë””ë ‰í† ë¦¬ ì •ë¦¬
        try:
            removed_dirs = 0
            for path in self.root.rglob("*"):
                if path.is_dir() and not any(path.iterdir()):
                    if path.name not in ['.git', 'venv', 'node_modules']:
                        path.rmdir()
                        removed_dirs += 1
            if removed_dirs:
                fixes_applied.append(f"ë¹ˆ ë””ë ‰í† ë¦¬ {removed_dirs}ê°œ ì œê±°")
        except:
            pass
        
        # 3. ê¶Œí•œ ë¬¸ì œ ìˆ˜ì • (Windows)
        if os.name == 'nt':
            try:
                # ê°„ë‹¨í•œ ê¶Œí•œ ì²´í¬ë§Œ
                test_file = self.root / ".test_write"
                test_file.write_text("test")
                test_file.unlink()
                fixes_applied.append("íŒŒì¼ ê¶Œí•œ ì •ìƒ í™•ì¸")
            except:
                pass
        
        return fixes_applied
    
    def _check(self, name: str, ok: bool, hint: str = "", severity: str = "medium"):
        """ì²´í¬ ê²°ê³¼ ê¸°ë¡"""
        status = "[PASS]" if ok else "[FAIL]"
        self.report.append((status, name, hint, severity))
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ê¸°ë¡
        try:
            with sqlite3.connect(self.diagnosis_db) as conn:
                conn.execute("""
                    INSERT INTO diagnosis_history (timestamp, check_name, status, details)
                    VALUES (?, ?, ?, ?)
                """, (datetime.now().isoformat(), name, status, hint))
        except:
            pass
    
    def _get_overall_status(self) -> str:
        """ì „ì²´ ìƒíƒœ íŒì •"""
        fails = [r for r in self.report if r[0] == "[FAIL]"]
        high_fails = [r for r in fails if r[3] == "high"]
        
        if high_fails:
            return "critical"
        elif fails:
            return "warning" 
        else:
            return "healthy"
    
    def _save_diagnosis_report(self, fixes_applied: List[str], optimizations: List[Dict]) -> str:
        """ì§„ë‹¨ ë³´ê³ ì„œ ì €ì¥"""
        reports_dir = self.root / "reports"
        reports_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = reports_dir / f"doctor_v3_{timestamp}.json"
        
        report_data = {
            "version": "3.0",
            "timestamp": timestamp,
            "status": self._get_overall_status(),
            "checks": [{"status": r[0], "name": r[1], "hint": r[2], "severity": r[3]} for r in self.report],
            "performance_metrics": self.performance_metrics,
            "predictions": self.predictions,
            "optimizations": optimizations,
            "auto_fixes_applied": fixes_applied,
            "summary": {
                "total_checks": len(self.report),
                "passed": len([r for r in self.report if r[0] == "[PASS]"]),
                "failed": len([r for r in self.report if r[0] == "[FAIL]"]),
                "predictions": len(self.predictions),
                "fixes_applied": len(fixes_applied)
            }
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        return str(report_file)

def run_doctor_v3(root_path: str = "C:/Users/eunta/multi-agent-workspace") -> Dict:
    """Doctor v3.0 ì‹¤í–‰"""
    doctor = DoctorV3(root_path)
    return doctor.run_comprehensive_diagnosis()

if __name__ == "__main__":
    result = run_doctor_v3()
    
    print(f"\nğŸ¥ Doctor v3.0 ì§„ë‹¨ ì™„ë£Œ!")
    print(f"ğŸ“Š ì „ì²´ ìƒíƒœ: {result['status']}")
    print(f"ğŸ”§ ìë™ ìˆ˜ì •: {result['fixes_applied']}ê°œ")
    print(f"ğŸ”® ì˜ˆì¸¡ ë¶„ì„: {result['predictions']}ê°œ")
    print(f"âš¡ ìµœì í™” ì œì•ˆ: {result['optimizations']}ê°œ")
    print(f"ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {result['report_file']}")