#!/usr/bin/env python3
"""
ìŠ¤ë§ˆíŠ¸ Scratchpad ê´€ë¦¬ ì‹œìŠ¤í…œ
- ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ìë™ ë¶„ë¥˜ ë° ì •ë¦¬
- AIë³„ ìë£Œ ìë™ ë¶„ë°°
- ì¤‘ìš” ìë£Œ ë³´ì¡´ ë° ê²€ìƒ‰
- ì„ì‹œ íŒŒì¼ ìë™ ì •ë¦¬
"""

import json
import os
import re
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

class SmartScratchpad:
    def __init__(self, workspace_path=None):
        if workspace_path is None:
            self.workspace_path = Path(__file__).parent.parent
        else:
            self.workspace_path = Path(workspace_path)
        
        self.scratchpad_path = self.workspace_path / "scratchpad"
        self.config_file = self.workspace_path / ".claude" / "scratchpad_config.json"
        self.index_file = self.scratchpad_path / "_index.json"
        
        # ê¸°ë³¸ ì„¤ì •
        self.default_config = {
            "auto_organize": True,
            "archive_after_days": 30,
            "max_temp_files": 50,
            "ai_routing": {
                "claude": ["architecture", "complex", "design", "security"],
                "codex": ["code", "implementation", "test", "debug"],
                "gemini": ["document", "analysis", "status", "log"]
            },
            "file_patterns": {
                "important": ["plan", "spec", "requirement", "design"],
                "temporary": ["temp", "tmp", "test", "debug"],
                "ai_specific": {
                    "claude": ["claude", "cl_", "for_claude"],
                    "codex": ["codex", "cd_", "for_codex"],
                    "gemini": ["gemini", "gm_", "for_gemini"]
                }
            }
        }
        
        self.ensure_structure()
        self.load_config()
    
    def ensure_structure(self):
        """Scratchpad ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        directories = [
            "incoming",      # ìƒˆë¡œ ë“¤ì–´ì˜¨ íŒŒì¼ë“¤
            "archive",       # ë³´ê´€ëœ íŒŒì¼ë“¤
            "ai_tasks",      # AIë³„ ì‘ì—… íŒŒì¼ë“¤
            "ai_tasks/claude",
            "ai_tasks/codex", 
            "ai_tasks/gemini",
            "important",     # ì¤‘ìš” ë¬¸ì„œë“¤
            "temp"          # ì„ì‹œ íŒŒì¼ë“¤
        ]
        
        for dir_name in directories:
            (self.scratchpad_path / dir_name).mkdir(parents=True, exist_ok=True)
    
    def load_config(self):
        """ì„¤ì • ë¡œë“œ"""
        if self.config_file.exists():
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = {**self.default_config, **json.load(f)}
        else:
            self.config = self.default_config.copy()
            self.save_config()
    
    def save_config(self):
        """ì„¤ì • ì €ì¥"""
        self.config_file.parent.mkdir(exist_ok=True)
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def analyze_file_content(self, file_path: Path) -> Dict:
        """íŒŒì¼ ë‚´ìš© ë¶„ì„í•˜ì—¬ ë¶„ë¥˜ ì •ë³´ ì¶”ì¶œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            # UTF-8ì´ ì•„ë‹Œ íŒŒì¼ ì²˜ë¦¬
            try:
                with open(file_path, 'r', encoding='cp949') as f:
                    content = f.read()
            except:
                return {"category": "binary", "ai_target": None, "importance": "unknown"}
        
        analysis = {
            "category": self.categorize_content(content),
            "ai_target": self.determine_ai_target(content, file_path.name),
            "importance": self.assess_importance(content, file_path.name),
            "keywords": self.extract_keywords(content),
            "size": len(content),
            "lines": content.count('\n') + 1
        }
        
        return analysis
    
    def categorize_content(self, content: str) -> str:
        """ì½˜í…ì¸  ë‚´ìš© ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        content_lower = content.lower()
        
        # ì½”ë“œ íŒŒì¼ ê°ì§€
        code_patterns = [
            r'def\s+\w+\(', r'function\s+\w+\(', r'class\s+\w+',
            r'import\s+\w+', r'from\s+\w+\s+import', r'#include',
            r'console\.log', r'print\(', r'System\.out\.println'
        ]
        if any(re.search(pattern, content) for pattern in code_patterns):
            return "code"
        
        # ì„¤ê³„/ê³„íš ë¬¸ì„œ
        if any(word in content_lower for word in ['architecture', 'design', 'plan', 'specification', 'requirement']):
            return "design"
        
        # ë¶„ì„/ë³´ê³ ì„œ
        if any(word in content_lower for word in ['analysis', 'report', 'findings', 'conclusion', 'summary']):
            return "analysis"
        
        # ë¡œê·¸/ìƒíƒœ
        if any(word in content_lower for word in ['log', 'status', 'error', 'debug', 'trace']):
            return "log"
        
        # ë¬¸ì„œ
        if any(word in content_lower for word in ['documentation', 'readme', 'guide', 'manual', 'help']):
            return "documentation"
        
        return "general"
    
    def determine_ai_target(self, content: str, filename: str) -> Optional[str]:
        """AI íƒ€ê²Ÿ ê²°ì •"""
        content_lower = content.lower()
        filename_lower = filename.lower()
        
        # íŒŒì¼ëª… ê¸°ë°˜ ë¼ìš°íŒ…
        for ai, patterns in self.config["file_patterns"]["ai_specific"].items():
            if any(pattern in filename_lower for pattern in patterns):
                return ai
        
        # ë‚´ìš© ê¸°ë°˜ ë¼ìš°íŒ…
        for ai, keywords in self.config["ai_routing"].items():
            if any(keyword in content_lower for keyword in keywords):
                return ai
        
        # ë³µì¡ë„ ê¸°ë°˜ ë¼ìš°íŒ…
        if len(content) > 5000 or content.count('\n') > 100:
            return "claude"  # ë³µì¡í•œ ë‚´ìš©ì€ Claudeì—ê²Œ
        elif "code" in content_lower or "function" in content_lower:
            return "codex"   # ì½”ë“œ ê´€ë ¨ì€ Codexì—ê²Œ
        elif "status" in content_lower or "log" in content_lower:
            return "gemini"  # ìƒíƒœ/ë¡œê·¸ëŠ” Geminiì—ê²Œ
        
        return None
    
    def assess_importance(self, content: str, filename: str) -> str:
        """ì¤‘ìš”ë„ í‰ê°€"""
        filename_lower = filename.lower()
        content_lower = content.lower()
        
        # íŒŒì¼ëª… ê¸°ë°˜ ì¤‘ìš”ë„
        if any(pattern in filename_lower for pattern in self.config["file_patterns"]["important"]):
            return "high"
        
        if any(pattern in filename_lower for pattern in self.config["file_patterns"]["temporary"]):
            return "low"
        
        # ë‚´ìš© ê¸°ë°˜ ì¤‘ìš”ë„
        high_importance_keywords = [
            "requirement", "specification", "architecture", "critical", 
            "important", "urgent", "deadline", "milestone"
        ]
        
        if any(keyword in content_lower for keyword in high_importance_keywords):
            return "high"
        
        # í¬ê¸° ê¸°ë°˜ ì¤‘ìš”ë„
        if len(content) > 10000:
            return "medium"
        elif len(content) < 500:
            return "low"
        
        return "medium"
    
    def extract_keywords(self, content: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš© ê°€ëŠ¥)
        words = re.findall(r'\b[a-zA-Zê°€-í£]{3,}\b', content.lower())
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = set(['the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 
                        'can', 'her', 'was', 'one', 'our', 'had', 'but', 'what'])
        
        # ë¹ˆë„ ê³„ì‚°
        word_freq = {}
        for word in words:
            if word not in stopwords and len(word) > 3:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ë°˜í™˜
        return sorted(word_freq.keys(), key=word_freq.get, reverse=True)[:10]
    
    def organize_file(self, file_path: Path) -> Dict:
        """íŒŒì¼ ìë™ ì •ë¦¬"""
        if not file_path.exists():
            return {"status": "error", "message": "File not found"}
        
        # íŒŒì¼ ë¶„ì„
        analysis = self.analyze_file_content(file_path)
        
        # ëª©ì ì§€ ê²°ì •
        destination = self.determine_destination(file_path, analysis)
        
        # íŒŒì¼ ì´ë™
        try:
            destination.parent.mkdir(parents=True, exist_ok=True)
            
            if destination.exists():
                # ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                name_parts = destination.name.rsplit('.', 1)
                if len(name_parts) == 2:
                    new_name = f"{name_parts[0]}_{timestamp}.{name_parts[1]}"
                else:
                    new_name = f"{destination.name}_{timestamp}"
                destination = destination.parent / new_name
            
            shutil.move(str(file_path), str(destination))
            
            # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
            self.update_index(destination, analysis)
            
            return {
                "status": "success",
                "original": str(file_path),
                "destination": str(destination),
                "analysis": analysis
            }
            
        except Exception as e:
            return {"status": "error", "message": str(e)}
    
    def determine_destination(self, file_path: Path, analysis: Dict) -> Path:
        """íŒŒì¼ ëª©ì ì§€ ê²°ì •"""
        base_name = file_path.name
        
        # ì¤‘ìš”ë„ë³„ ì²˜ë¦¬
        if analysis["importance"] == "high":
            return self.scratchpad_path / "important" / base_name
        
        # AI íƒ€ê²Ÿë³„ ì²˜ë¦¬
        if analysis["ai_target"]:
            return self.scratchpad_path / "ai_tasks" / analysis["ai_target"] / base_name
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬
        if analysis["category"] == "log":
            return self.scratchpad_path / "archive" / "logs" / base_name
        elif analysis["importance"] == "low":
            return self.scratchpad_path / "temp" / base_name
        else:
            return self.scratchpad_path / "archive" / base_name
    
    def update_index(self, file_path: Path, analysis: Dict):
        """íŒŒì¼ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸"""
        # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ
        if self.index_file.exists():
            with open(self.index_file, 'r', encoding='utf-8') as f:
                index = json.load(f)
        else:
            index = {"files": {}, "last_updated": None}
        
        # íŒŒì¼ ì •ë³´ ì¶”ê°€
        relative_path = file_path.relative_to(self.scratchpad_path)
        index["files"][str(relative_path)] = {
            **analysis,
            "added_date": datetime.now().isoformat(),
            "file_size": file_path.stat().st_size if file_path.exists() else 0
        }
        
        index["last_updated"] = datetime.now().isoformat()
        
        # ì¸ë±ìŠ¤ ì €ì¥
        with open(self.index_file, 'w', encoding='utf-8') as f:
            json.dump(index, f, indent=2, ensure_ascii=False)
    
    def search_files(self, query: str) -> List[Dict]:
        """íŒŒì¼ ê²€ìƒ‰"""
        if not self.index_file.exists():
            return []
        
        with open(self.index_file, 'r', encoding='utf-8') as f:
            index = json.load(f)
        
        results = []
        query_lower = query.lower()
        
        for file_path, info in index["files"].items():
            # íŒŒì¼ëª… ê²€ìƒ‰
            if query_lower in file_path.lower():
                results.append({"path": file_path, "info": info, "match_type": "filename"})
                continue
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰
            if any(query_lower in keyword for keyword in info.get("keywords", [])):
                results.append({"path": file_path, "info": info, "match_type": "keyword"})
                continue
            
            # ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰
            if query_lower in info.get("category", "").lower():
                results.append({"path": file_path, "info": info, "match_type": "category"})
        
        return results
    
    def cleanup_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        temp_dir = self.scratchpad_path / "temp"
        if not temp_dir.exists():
            return
        
        # ì˜¤ë˜ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        cutoff_date = datetime.now() - timedelta(days=7)
        deleted_count = 0
        
        for file_path in temp_dir.iterdir():
            if file_path.is_file():
                file_date = datetime.fromtimestamp(file_path.stat().st_mtime)
                if file_date < cutoff_date:
                    file_path.unlink()
                    deleted_count += 1
        
        return deleted_count
    
    def generate_ai_assignment_report(self) -> str:
        """AIë³„ í• ë‹¹ëœ ì‘ì—… ë³´ê³ ì„œ ìƒì„±"""
        if not self.index_file.exists():
            return "ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
        
        with open(self.index_file, 'r', encoding='utf-8') as f:
            index = json.load(f)
        
        ai_stats = {"claude": [], "codex": [], "gemini": [], "unassigned": []}
        
        for file_path, info in index["files"].items():
            ai_target = info.get("ai_target", "unassigned")
            if ai_target in ai_stats:
                ai_stats[ai_target].append(file_path)
            else:
                ai_stats["unassigned"].append(file_path)
        
        report = f"""# ğŸ¤– AI ì‘ì—… ë¶„ë°° í˜„í™©

**ìƒì„± ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š ë¶„ë°° í†µê³„
"""
        
        for ai, files in ai_stats.items():
            emoji = {"claude": "ğŸ§ ", "codex": "âš¡", "gemini": "ğŸ“–", "unassigned": "â“"}[ai]
            report += f"- {emoji} **{ai.title()}**: {len(files)}ê°œ íŒŒì¼\n"
        
        report += "\n## ğŸ“‹ ìƒì„¸ ë‚´ì—­\n\n"
        
        for ai, files in ai_stats.items():
            if files:
                emoji = {"claude": "ğŸ§ ", "codex": "âš¡", "gemini": "ğŸ“–", "unassigned": "â“"}[ai]
                report += f"### {emoji} {ai.title()}\n"
                for file_path in files[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                    report += f"- `{file_path}`\n"
                if len(files) > 10:
                    report += f"- ... ì™¸ {len(files) - 10}ê°œ íŒŒì¼\n"
                report += "\n"
        
        return report

# CLI ì‹¤í–‰ì„ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    import sys
    
    scratchpad = SmartScratchpad()
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "organize":
            if len(sys.argv) > 2:
                file_path = Path(sys.argv[2])
                result = scratchpad.organize_file(file_path)
                print(json.dumps(result, indent=2, ensure_ascii=False))
            else:
                print("ì‚¬ìš©ë²•: python smart_scratchpad.py organize <file_path>")
        
        elif command == "search":
            if len(sys.argv) > 2:
                query = sys.argv[2]
                results = scratchpad.search_files(query)
                print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
                for result in results[:10]:
                    print(f"- {result['path']} ({result['match_type']})")
            else:
                print("ì‚¬ìš©ë²•: python smart_scratchpad.py search <query>")
        
        elif command == "cleanup":
            deleted = scratchpad.cleanup_temp_files()
            print(f"ğŸ§¹ {deleted}ê°œì˜ ì„ì‹œ íŒŒì¼ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        
        elif command == "report":
            report = scratchpad.generate_ai_assignment_report()
            print(report)
        
        else:
            print("ì‚¬ìš©ë²•: python smart_scratchpad.py [organize|search|cleanup|report]")
    else:
        # ê¸°ë³¸: ìƒíƒœ ì¶œë ¥
        if scratchpad.index_file.exists():
            with open(scratchpad.index_file, 'r', encoding='utf-8') as f:
                index = json.load(f)
            file_count = len(index.get("files", {}))
            print(f"ğŸ“ Scratchpad: {file_count}ê°œ íŒŒì¼ ê´€ë¦¬ ì¤‘")
        else:
            print("ğŸ“ Scratchpad: ì´ˆê¸°í™” í•„ìš”")